use std::collections::HashSet;
use crate::model::demo::Model as DemoModel;
use burn::Tensor;
use burn::backend::{NdArray, WebGpu};
use burn::backend::wgpu::graphics::AutoGraphicsApi;
use burn::backend::wgpu::{init_setup_async, WgpuDevice};
use burn::module::Module;
use burn::prelude::Backend;
use burn::record::{BinBytesRecorder, FullPrecisionSettings, Recorder};
use burn::tensor::DataError;
use tracing::debug;
use othello::othello_game::{Color, OthelloGame};

/// An element in the policy vector in form ((row, col), probability)
pub(crate) type PolicyElement = ((usize, usize), f32);

/// A tuple containing the policy vector, and an evaluation scalar
pub(crate) type PolicyVectorWithEvaluation = (Vec<PolicyElement>, f32);

#[allow(clippy::large_enum_variant)]
/// The model is loaded to a specific backend
pub enum ModelType {
    /// The model is loaded to the NdArray backend
    WithNdArrayBackend(NeuralNet<NdArray<f32>>),

    /// The model is loaded to the WebGpu backend
    WithWgpuBackend(NeuralNet<WebGpu<f32, i32>>),
}

/// Neural network
pub struct NeuralNet<B: Backend> {
    model: DemoModel<B>,
}

/// Embedded model weights (generated by othello-model-gen)
static MODEL_BYTES: &[u8] = include_bytes!("../model.bin");

impl<B: Backend> NeuralNet<B> {
    pub async fn new(device: &B::Device) -> Self {
        tracing::info!("Initialising WASM");
        init_setup_async::<AutoGraphicsApi>(&WgpuDevice::default(), Default::default()).await;
        tracing::info!("Initialised WASM");

        tracing::info!("Loading model weights...");
        
        // Create empty model structure
        let model: DemoModel<B> = DemoModel::new(device);
        
        // Load weights using BinBytesRecorder (no blocking/condvar operations)
        let record = BinBytesRecorder::<FullPrecisionSettings, &'static [u8]>::default()
            .load(MODEL_BYTES, device)
            .expect("Failed to load model weights");
        
        let model = model.load_record(record);
        tracing::info!("Model loaded successfully");

        Self { model }
    }

    pub async fn forward(&self, input: Tensor<B, 4>) -> Result<(Vec<f32>, f32), DataError> {
        let outputs = self.model.forward(input);

        let policy: Vec<f32> = outputs
            .0
            .to_data_async()
            .await
            .unwrap()
            .convert::<f32>()
            .to_vec()?;
        let value_array: Vec<f32> = outputs
            .1
            .to_data_async()
            .await
            .unwrap()
            .convert::<f32>()
            .to_vec()?;
        let value = value_array[0];

        Ok((policy, value))
    }
}

pub async fn async_nn_evaluate<B: Backend>(
    model: &NeuralNet<B>,
    game: &OthelloGame,
    player: &Color,
) -> Result<(Vec<(usize,f32)>, f32), DataError> {
    debug!("async eval on {game}");
    let mut data = [[[[0.0f32; 8]; 8]; 2]; 1];

    for row in 0..8 {
        for col in 0..8 {
            if let Some(c) = game.get(row, col) {
                match (player, c) {
                    (Color::White, Color::White) | (Color::Black, Color::Black) => {
                        data[0][0][row][col] = 1.0;
                    }
                    _ => {
                        data[0][1][row][col] = 1.0;
                    }
                }
            }
        }
    }

    let input = Tensor::<B, 4>::from_floats(data, &B::Device::default());

    let (log_policy, value) = model.forward(input).await?;
    let policy: Vec<f32> = log_policy.iter().map(|&lp| lp.exp()).collect();

    let legal_set: HashSet<usize> = game.legal_moves(*player).iter().map(|(r, c)| r * 8 + c).collect();

    let filtered: Vec<(usize, f32)> = policy
        .into_iter()
        .enumerate()
        .filter(|(a, _)| legal_set.contains(a))
        .collect();

    let sum: f32 = filtered.iter().map(|(_, p)| p).sum();

    let filtered_policy: Vec<(usize, f32)> = filtered.into_iter().map(|(a, p)| (a, p / sum)).collect();

    Ok((filtered_policy, value))
}
